<?xml version="1.0" encoding="UTF-8"?>    
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>  

<configuration>
    <!-- dfs.nameservices 命名空间的逻辑名称，多个用,分割 -->
    <property>
        <name>dfs.nameservices</name>
        <value>bigha</value>
    </property>

    <!-- 指定ns1下有两个namenode，分别是nn1,nn2 -->
    <property>
        <name>dfs.ha.namenodes.bigha</name>
        <value>nn1,nn2</value>
    </property>

    <!-- 指定nn1的RPC通信地址 -->
    <property>
        <name>dfs.namenode.rpc-address.bigha.nn1</name>
        <value>node0:8020</value>
    </property>

    <!-- 指定nn1的HTTP通信地址 -->
    <property>
        <name>dfs.namenode.http-address.bigha.nn1</name>
        <value>node0:50070</value>
    </property>

    <!-- 指定nn2的RPC通信地址 -->
    <property>
        <name>dfs.namenode.rpc-address.bigha.nn2</name>
        <value>node1:8020</value>
    </property>

    <!-- 指定nn2的HTTP通信地址 -->
    <property>
        <name>dfs.namenode.http-address.bigha.nn2</name>
        <value>node1:50070</value>
    </property>

    <!-- 指定namenode的元数据存放的Journal Node的地址，必须基数，至少三个 -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://node2:8485;node3:8485;node4:8485/bigha</value>
    </property>

    <!--这是JournalNode进程保持逻辑状态的路径。这是在linux服务器文件的绝对路径-->
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/opt/ws/hadoop/journal/</value>
    </property>

    <!-- 开启namenode失败后自动切换 -->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

    <!-- 配置失败自动切换实现方式 -->
    <property>
        <name>dfs.client.failover.proxy.provider.bigha</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>

    <!-- 配置隔离机制方法，多个机制用换行分割 -->
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>
            sshfence
            shell(/bin/true)
        </value>
    </property>

    <!-- 使用sshfence隔离机制时需要ssh免登陆 -->
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/lidong/.ssh/id_rsa</value>
    </property>

    <!-- 配置sshfence隔离机制超时时间30秒 -->
    <property>
        <name>dfs.ha.fencing.ssh.connect-timeout</name>
        <value>30000</value>
    </property>

    <!-- 指定磁盘预留多少空间，防止磁盘被撑满用完，单位为bytes -->
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>2147483648</value>
    </property>  

    <!--指定namenode名称空间的存储地址-->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///opt/ws/hadoop/hdfs/name</value>
    </property>

    <!--指定datanode数据存储地址-->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///opt/ws/hadoop/hdfs/data</value>
    </property>

    <!--指定数据冗余份数-->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property> 

    <!--指定可以通过web访问hdfs目录-->
    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>  

    <!-- 处理namenode线程数 -->
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>200</value>
        <description>The number of server threads for the namenode.</description>
    </property>

    <!-- 处理datanode线程数 -->
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>200</value>
        <description>The number of server threads for the datanode.</description>
    </property>

    <!-- 数据传输最大线程数-->
    <property>
        <name>dfs.datanode.max.transfer.threads</name>
        <value>1024</value>
    </property>    

    <!-- 设置块大小 -->
    <property>
        <name>dfs.blocksize</name>
        <value>2097152</value>
    </property>

<!--     <property>
   -         <name>dfs.namenode.fs-limits.min-block-size</name>
   -         <value>1048576</value>
   -     </property>
   - 
   -     <property>
   -         <name>dfs.namenode.fs-limits.max-blocks-per-file</name>
   -         <value>1048576</value>
   -     </property> -->

</configuration>
