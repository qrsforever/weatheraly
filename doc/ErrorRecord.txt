1. NameNode挂掉
  错误日志:
    2017-07-10 13:10:59,325 FATAL org.apache.hadoop.hdfs.server.namenode.FSEditLog: Error: flush failed for required journal (JournalAndStream(mgr=QJM to [192.168.1.202:8485, 192.168.1.203:8485, 192.168.1.204:8485], stream=QuorumOutputStream starting at txid 2396))
    java.io.IOException: Timed out waiting 20000ms for a quorum of nodes to respond.
    	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:137)
    	at org.apache.hadoop.hdfs.qjournal.client.QuorumOutputStream.flushAndSync(QuorumOutputStream.java:107)
    	at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:113)
    	at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:107)
    	at org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalSetOutputStream$8.apply(JournalSet.java:533)
    	at org.apache.hadoop.hdfs.server.namenode.JournalSet.mapJournalsAndReportErrors(JournalSet.java:393)
    	at org.apache.hadoop.hdfs.server.namenode.JournalSet.access$100(JournalSet.java:57)
    	at org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalSetOutputStream.flush(JournalSet.java:529)
    	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSync(FSEditLog.java:707)
    	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSyncAll(FSEditLog.java:604)
    	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.endCurrentLogSegment(FSEditLog.java:1346)
    	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.rollEditLog(FSEditLog.java:1279)
    	at org.apache.hadoop.hdfs.server.namenode.FSImage.rollEditLog(FSImage.java:1227)
    	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5056)
    	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1216)
    	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:141)
    	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
    	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
    	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
    	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)
    	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)
    	at java.security.AccessController.doPrivileged(Native Method)
    	at javax.security.auth.Subject.doAs(Subject.java:422)
    	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
    	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2455)
    2017-07-10 13:10:59,326 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Aborting QuorumOutputStream starting at txid 2396
    2017-07-10 13:10:59,326 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
    2017-07-10 13:10:59,329 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
    /************************************************************
    SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
    ************************************************************/

    解决:
        https://community.hortonworks.com/questions/38523/name-node-instability-flush-failed-for-required-jo.html
        调整内存大小

2. mapreduce内存配置错误
    错误日志:
    17/07/10 17:22:43 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/lidong/.staging/job_1499678282034_0001
    Exception in thread "main" java.io.IOException: org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=1536, maxMemory=1024
	    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:279)
	    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:248)
	    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:219)
	    at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:402)
	    at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:341)
	    at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:284)
	    at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:618)
	    at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:257)
	    at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:499)
	    at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	    at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)
	    at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)
	    at java.security.AccessController.doPrivileged(Native Method)
	    at javax.security.auth.Subject.doAs(Subject.java:422)
	    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2455)

    解决:
        http://wenda.chinahadoop.cn/question/2862
        最大请求内存比实际设置的物理内存大, 矛盾产生
        调整内存大小


3. Logs页面打不开:
    错误提示:
        Failed redirect for container_1499824754337_0001_01_000001
        Failed while trying to construct the redirect url to the log server. Log Server url may not be configured
        java.lang.Exception: Unknown container. Container either has not started or has already completed or doesn't belong to this node at all.

    解决:
        配置属性:yarn.log.server.url 

4. Avro引入mapreduce jar包,错误:
    错误提示:
        java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.avro.mapreduce.AvroKeyOutputFormat not found

    解决:
        (写到hadoop-evn.sh)
        export HADOOP_USER_CLASSPATH_FIRST=true
        export AVRO_VER=1.8.2
        export HADOOP_CLASSPATH="$AVRO_HOME/avro-${AVRO_VER}.jar:$AVRO_HOME/avro-mapred-${AVRO_VER}-hadoop2.jar"
        同时-libjars指定(或许是hadoop的bug)
        hadoop jar target/datapaser-1.0.0.jar com.weatheraly.bigdata.DataParseApp -libjars xxx1.jar:xxx2.jar inputdir outputdir

5. Avro的jar包版本不统一
    错误提示:
        Error: org.apache.avro.generic.GenericData.createDatumWriter(Lorg/apache/avro/Schema;)Lorg/apache/avro/io/DatumWriter;
    
    解决:
        Hadoop2.8版本自带avro版本1.7.4, 项目中使用1.8.2, 而createDatumWriter函数再1.8.2中引入.
        最简单的方式直接替换掉原来的

6. Hbase的库找不到
    错误提示:
        Exception in thread "main" java.lang.NoClassDefFoundError: org/apache/hadoop/hbase/HBaseConfiguration
        	at com.weatheraly.bigdata.DataParseApp.createHBaseTable(DataParseApp.java:60)
        	at com.weatheraly.bigdata.DataParseApp.run(DataParseApp.java:105)
        	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
        	at com.weatheraly.bigdata.DataParseApp.main(DataParseApp.java:91)
        	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        	at java.lang.reflect.Method.invoke(Method.java:497)
        	at org.apache.hadoop.util.RunJar.run(RunJar.java:234)
        	at org.apache.hadoop.util.RunJar.main(RunJar.java:148)
        Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.HBaseConfiguration
        	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
        	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)

    解决: (hadoop-env.sh)
        export HBASE_HOME=/opt/hbase
        for f in $HBASE_HOME/lib/*.jar; do                        
            if [ "$HBASE_CLASSPATH" ]; then
                export HBASE_CLASSPATH=$HBASE_CLASSPATH:$f
            else
                export HBASE_CLASSPATH=$f
            fi
        done
        export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$HBASE_CLASSPATH
 

7. 运行主机不对
    错误:
         INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=180000 watcher=hconnection
         INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181
         WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
         java.net.ConnectException: Connection refused
    解决:
         hadoop 运行程序没有读到hbase的配置文件hbase.zookeeper.quorum 
         将hbase-site.xml放到hadoop/etc/hadoop中

8. log4j多个不同版本jar包
    错误:
        SLF4J: Class path contains multiple SLF4J bindings.
        SLF4J: Found binding in [jar:file:/data/opt/hadoop/hadoop-2.8.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
        SLF4J: Found binding in [jar:file:/data/opt/hbase/hbase-1.3.1/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
        SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
        SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

    解决:
        # hadoop-evn.sh 过滤
        export HBASE_HOME=/opt/hbase
        for f in $HBASE_HOME/lib/*.jar; do
            # 过滤冲突jar包
            bf=`basename $f`
            hh=${bf%%-*}
            if [ slf4j == $hh -o log4j == $hh ]; then
                continue
            fi
            if [ "$HBASE_CLASSPATH" ]; then
                export HBASE_CLASSPATH=$HBASE_CLASSPATH:$f
            else
                export HBASE_CLASSPATH=$f
            fi
        done
        export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$HBASE_CLASSPATH

        (暴力点替换)

9. 在没搭建HBase环境的主机上运行hadoop jar(hbase)出错
    错误:
        17/07/14 19:30:42 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/192.168.1.200:2181. Will not attempt to authenticate using SASL (unknown error)
        17/07/14 19:30:42 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
        java.net.ConnectException: Connection refused
        	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
        	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
        	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
    
    解决:
        这个和没有没搭建hbase无关, 犯了一个错误, 需要把hbase相关的配置hbase-site.xml放到hadoop的配置文件中.
        结论来源于源码, HBaseConfiguration --> Configuration (加载配置时统一使用hadoop目录下的)


10. 
    错误:
        Exception in thread "main" org.apache.hadoop.hbase.client.RetriesExhaustedException: Can't get the locations
        	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:319)
        	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
        	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
        	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:212)
        	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:314)
        	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:289)
        	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:164)
        	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:159)
        	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:796)
        	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
        	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
        	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:408)
        	at com.weatheraly.bigdata.DataParseApp.createHBaseTable(DataParseApp.java:74)
        	at com.weatheraly.bigdata.DataParseApp.run(DataParseApp.java:107)
        	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
        	at com.weatheraly.bigdata.DataParseApp.main(DataParseApp.java:92)
        	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        	at java.lang.reflect.Method.invoke(Method.java:497)
        	at org.apache.hadoop.util.RunJar.run(RunJar.java:234)
        	at org.apache.hadoop.util.RunJar.main(RunJar.java:148)
        17/07/14 21:14:21 INFO zookeeper.ClientCnxn: EventThread shut down for session: 0x15d413a16740007

        ROOT CAUSE
        This happens when user has an incorrect value defined for "zookeeper.znode.parent" in the hbase-site.xml sourced on the client side or in case of a custom API written , the "zookeeper.znode.parent" was incorrectly updated to a wrong location . For example the default "zookeeper.znode.parent" is set to "/hbase-unsecure" , but if you incorrectly specify that as lets say "/hbase" as opposed to what we have set up in the cluster, we will encounter this exception while trying to connect to the HBase cluster.
        RESOLUTION
        The solution here would be to update the hbase-site.xml / source out the same hbase-site.xml from the cluster or update the HBase API to correctly point out the "zookeeper.znode.parent" value as updated in the HBase cluster.

11. 日志时间与系统时间不匹配
    解决:
    1. 局部解决(不推荐)
        export HADOOP_NAMENODE_OPTS="-Duser.timezone=GMT+08"
    2. 全局解决
        # 使用vagrant/common/linux/etc/下的配置
        if [ -f $COMMON_DIR/linux/etc/localtime ];
        then
            rm /etc/localtime
        fi
        if [ -f $COMMON_DIR/linux/etc/timezone ];
        then
            rm /etc/timezone
        fi
        cp $COMMON_DIR/linux/etc/* /etc

12. 
    错误:
        2017-07-17 18:01:32,428 WARN  [regionserver/localhost/192.168.1.202:16020] regionserver.HRegionServer: error telling master we are up
        com.google.protobuf.ServiceException: java.net.ConnectException: Connection refused
        	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:240)
        	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$BlockingRpcChannelImplementation.callBlockingMethod(AbstractRpcClient.java:336)
        	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.regionServerStartup(RegionServerStatusProtos.java:8982)
        	at org.apache.hadoop.hbase.regionserver.HRegionServer.reportForDuty(HRegionServer.java:2335)
        	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:929)
        	at java.lang.Thread.run(Thread.java:745)
        Caused by: java.net.ConnectException: Connection refused
        	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
        	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
        	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
        	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
        	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupConnection(RpcClientImpl.java:416)
        	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.setupIOstreams(RpcClientImpl.java:722)
        	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.writeRequest(RpcClientImpl.java:909)
        	at org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.tracedWriteRequest(RpcClientImpl.java:873)
        	at org.apache.hadoop.hbase.ipc.RpcClientImpl.call(RpcClientImpl.java:1244)
        	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.callBlockingMethod(AbstractRpcClient.java:227)
        	... 5 more
        2017-07-17 18:01:32,428 WARN  [regionserver/localhost/192.168.1.202:16020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
        2017-07-17 18:01:35,429 INFO  [regionserver/localhost/192.168.1.202:16020] regionserver.HRegionServer: reportForDuty to master=localhost,16000,1500284427448 with port=16020, startcode=1500284423534
        2017-07-17 18:01:35,429 WARN  [regionserver/localhost/192.168.1.202:16020] regionserver.HRegionServer: error telling master we are up
        

        2017-07-17 19:58:39,691 INFO  [localhost:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 134079 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
        2017-07-17 19:58:41,196 INFO  [localhost:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 135584 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
        2017-07-17 19:58:42,700 INFO  [localhost:16000.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 137088 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
    
    建议:
        /etc/hosts 里面还必须有127.0.0.1 localhost这一项

13. hbase.version 问题, 实际上是clusterID不匹配问题
    错误:
        2017-07-17 20:31:57,010 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/opt/ws/hadoop/hdfs/data/
        java.io.IOException: Incompatible clusterIDs in /home/lidong/workspace/hadoop/hdfs/data: namenode clusterID = CID-9341723c-cd5d-4f4e-bba3-190f581d1a1f; datanode clusterID = CID-f2f1c1e3-1ec5-4f22-a41f-8814fcf36521
        	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
        	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
        	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
        	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
        	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
        	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1566)
        	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1527)
        	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:327)
        	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:266)
        	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:746)
        	at java.lang.Thread.run(Thread.java:745)
    原因:
        clusterIDs不统一导致, 可能是由于自己重新格式化namenode导致 (start-cluster.sh 1)

    解决:
        stop-cluster.sh
        start-vm.sh 1
        
14. Hbase如何基于NameNode的HA进行配置问题
    错误:
        17/07/17 21:00:41 WARN wal.WALProcedureStore: Log directory not found: File hdfs://bigha/hbase/MasterProcWALs does not exist. 
    解决:
        Add a pointer to your HADOOP_CONF_DIR to the HBASE_CLASSPATH environment variable in hbase-env.sh.
        Add a copy of hdfs-site.xml (or hadoop-site.xml) or, better, symlinks, under ${HBASE_HOME}/conf, or

15. logs目录不存在
    错误:
        2017-07-19 13:06:11,050 ERROR org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService: Error reading root log dir this deletion attempt is being aborted
        java.io.FileNotFoundException: File /opt/ws/hadoop/tmp/logs does not exist.
        	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:795)
        	at org.apache.hadoop.hdfs.DistributedFileSystem.access$700(DistributedFileSystem.java:106)
        	at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:853)
        	at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:849)
        	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:849)
        	at org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService$LogDeletionTask.run(AggregatedLogDeletionService.java:82)
        	at java.util.TimerThread.mainLoop(Timer.java:555)
        	at java.util.TimerThread.run(Timer.java:505)
    解决:
        (yarn.nodemanager.remote-app-log-dir)目录是hdfs分布式系统的,不是node节点的, 改回去

16. HBase 包找不到
    错误:
        2017-07-19 13:30:55,475 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1500440310693_0001_000001
        2017-07-19 13:30:55,839 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
        2017-07-19 13:30:55,839 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1500440310693 } attemptId: 1 } keyId: -1359864145)
        2017-07-19 13:30:56,121 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
        2017-07-19 13:30:56,139 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
        2017-07-19 13:30:56,220 INFO [main] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.app.MRAppMaster failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.hbase.mapreduce.TableOutputFormat not found
        org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.hbase.mapreduce.TableOutputFormat not found
        	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$2.call(MRAppMaster.java:518)
        	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$2.call(MRAppMaster.java:498)
        	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.callWithJobClassLoader(MRAppMaster.java:1593)
        	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.createOutputCommitter(MRAppMaster.java:498)
        	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceInit(MRAppMaster.java:284)
        	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
        	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$5.run(MRAppMaster.java:1551)
        	at java.security.AccessController.doPrivileged(Native Method)
    解决:
        默认YARN找库路径在yarn.application.classpath 

17. HTTP页面错误refused
    错误:
        Problem accessing /proxy/application_1500464545519_0001/. Reason:
        
           Connection to http://node4:8088 refused
    解决:
        //TODO


18. Reduce halt
    错误:
        2017-07-19 19:45:40,415 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:4 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:1 CompletedReds:0 ContAlloc:1 ContRel:0 HostLocal:1 RackLocal:0
        2017-07-19 19:45:40,422 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1500464545519_0001_01_000002
        2017-07-19 19:45:40,422 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1500464545519_0001_m_000000_0: Container killed by the ApplicationMaster.
        Container killed on request. Exit code is 143
        Container exited with a non-zero exit code 143
    解决:
        //TODO
